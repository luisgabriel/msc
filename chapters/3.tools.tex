\chapter{Measuring Energy Consumption}\label{chapter:tools}
Measuring the energy consumption of a computer system is a broad area of research. There are several ways we can accomplish this task. They can be categorized into two separate approaches: power measurement and energy estimation. The first one, power measurement, makes use of special power measurement hardware to collect power samples of the running system. These samples are often measured in watts. We can then obtain the energy (in joules) multiplying the power by the time: $E = P \times t$.
%There are several power meters currently available in the market that can be used to collect this kind of data. Depending on the manufacturer, these power meters can have different characteristics. One of the most important is sampling rate, which defines the number of samples of power the is collected per second. It can vary from 1 to 1,000 samples per second. The higher the sampling rate, more accurate the final energy measurement will be.
The second approach, energy estimation, uses software-based techniques to predict how much energy the system is consuming at runtime. It collects data from the running system to be used as predictors of energy consumption. For instance, powertop\footnote{https://01.org/powertop} is a Linux tool that uses this approach. It monitors CPU states, devices drivers and kernel options to report how the active components of the system are behaving regarding power consumption.

For this work, we chose to use an energy estimation approach for measuring the energy consumption of Haskell programs. In \secref{sec:rapl}, we present more details about \acs{rapl}, which is the technique we chose. Later, in \secref{sec:profiler} and \secref{sec:criterion}, we present two different performance analysis tools of the Haskell ecosystem: the \acs{ghc} profiler and Criterion. We explain how these tools work and how we extended them also to analyze energy consumption.

\section{RAPL}\label{sec:rapl}
\ac{rapl}~\citep{david:2010} is an interface designed by Intel to enable chip-level power management. It was introduced with the Sandy Bridge microarchitecture. Nowadays, \acs{rapl} is widely supported by the Intel architectures, including Xeon family CPUs, that targets server systems, and the popular Core i5 and i7 families, that targets domestic use. This interface provides a set of counters with energy and power consumption information. To estimate energy consumption, \acs{rapl} uses a software power model. This model is based on various hardware performance counters, temperature, leakage models and I/O models~\citep{weaver:2012}. Its precision and reliability has been extensively studied~\citep{rotem:2012,hahnel:2012}.

\begin{table}[htp]
	\caption{List of available \ac{rapl} domains.}
	\label{tbl:rapl-sensors}
	\centering
	\rowcolors{1}{lightgray!30}{white}
	\begin{tabular}{ll}
	  \toprule
	  \texttt{PKG}  & The entire CPU socket\\
    \texttt{PP0}  & Processor cores and caches (Core devices)\\
    \texttt{PP1}  & The on-chip GPU (Uncore devices)\\
    \texttt{DRAM} & Memory controller\\
	  \bottomrule
	\end{tabular}
\end{table}

With \ac{rapl}, developers can monitor energy consumption and set power limits. The access to this information is divided into different domains, which provides fine grained reports and control. \tabref{tbl:rapl-sensors} list these domains. Each domain is a physically meaningful domain for power management, as we can see in \figref{fig:power-planes}. The \ac{rapl} domains available in a platform vary across product segments. Tipically, the desktop platforms have access to \{\texttt{PKG}, \texttt{PP0}, \texttt{PP1}\}, while the server platforms have access to \{\texttt{PKG}, \texttt{PP0}, \texttt{DRAM}\}.
% talk about what each RAPL domain supports?
% source: 01.org/blogs/tlcounts/2014/running-average-power-limit-%E2%80%93-rapl

\begin{savenotes}
\begin{figure}[htp]
  \centering
  \caption{An example of report generated by the \ac{ghc} profiler with energy metrics}
  \includegraphics[width=\columnwidth]{images/power-planes-placeholder}
  \footnotesize{Source: Made by the author. Inspired on images from the "Intel® Power Governor" article\footnote{https://software.intel.com/en-us/articles/intel-power-governor}.}
  \label{fig:power-planes}
\end{figure}
\end{savenotes}

The interaction with \acs{rapl} is done via \acp{msr}. \acp{msr} are special control registers present in the x86 instruction set that are tipically used for debugging, monitoring performance and toggling CPU features. Accessing \acp{msr} requires ring-0 access to the hardware, which is typically only allowed to the operating system kernel. This means that accessing the \ac{rapl} readings requires a kernel driver. In Linux, we do not have an specific driver to access the \ac{rapl} \acp{msr}. Instead, we have a generic \texttt{msr} driver (or kernel module) that exports \ac{msr} access to the userspace. The register readings are exposed as files inside the CPU device directories (e.g. \texttt{/dev/cpu/0/msr}). These files have read-only permission for superusers (root).

As we can see, manipulating these registers is not a straightforward process. To do this, developers need some knowledge of system programming and familiarity with the processor instruction set to know how to interpret the raw values exposed by the readings. Also, developers using \ac{rapl} need to handle possible register overflows. In a high power consumption scenario, \ac{rapl} \acp{msr} have a wraparound time of around 60 secs~\citep{intel:2016}. So to abstract these low-level interfaces from Haskell developers, we present in the next sections two performance analisys tool that we extended to work with \ac{rapl}.


\section{GHC Profiler}\label{sec:profiler}
A profiler is a tool for helping the development of efficient programs. Its main function is to provide the necessary information for developers to identify performance bottlenecks. So that once the hot spots in a program have been identified, the developer can work on the code to improve its performance and continuously check the effect of each modification. To achieve this goal, a profiler should keep track of important program resources. Moreover, the data gathered by the profiler must be related to the program source code in a way that is meaningful to the developer. This is usually accomplished by reporting the measurements by program structures (e.g. functions or methods) or source code structures (e.g. lines).

However, it is hard to establish this correspondence between measurements and source code for high-level languages. Usually, these languages provide abstractions and constructs that are unrelated to the way that the underlying execution engine works. Haskell is not different. Features such as polymorphism, high-order functions, and lazy evaluation make this task even harder. For example, in the presence of lazy evaluation, the evaluation of an expression can be interleaved with the evaluation of the inputs that this expression demands. This makes the resulting order of execution of expressions to bear no resemblance to the source code.

To address this problem, the \ac{ghc} profiler uses \emph{cost centres}~\citep{sansom:1995}. They are the logical components of the program to which the profiler associate the gathered data. A cost centre is simply a label to which we attribute execution costs. They are represented by annotations around expressions. So the costs incurred by the evaluation of the annotated expression are assigned to the enclosing cost centre. The cost centres can be automatically generated by the compiler or manually specified by the developer through the \texttt{\{-\# SCC \#-\}} directive. In \autoref{code:prof-mean}\footnote{This code example was extracted from \cite{sullivan:2008}}, we show an example of how it can be manually specified by the developer (line 10). In this example, all the costs incurred by the evaluation of \texttt{sum xs / fromIntegral (length xs)} will be attributed to the \texttt{mean} cost centre. It is important to point out that cost centres have a formally defined semantics~\citep{sansom:1995} that specifies how the cost attribution works.

\begin{listing}
  \caption{A Haskell program to calculate the mean of a list of numbers}
  \begin{minted}{haskell}
import System.Environment
import Text.Printf

main :: IO ()
main = do
    [d] <- map read `fmap` getArgs
    printf "%f\n" (mean [1..d])

mean :: [Double] -> Double
mean xs = {-# SCC mean #-} sum xs / fromIntegral (length xs)
  \end{minted}
  \label{code:prof-mean}
\end{listing}

Currently, the \ac{ghc} profiler it is capable of measuring time and space usage. In \ac{ghc}, the profiler is part of the runtime system, which means that the profiling routines are contained within the final program executable. So to build a program for profiling, we need to pass to \ac{ghc} the \texttt{-prof} flag when compiling it. Then, to run this program in profiling mode, we need to specify it to the runtime system by passing the \texttt{+RTS -p} argument. It makes the runtime system collect time and memory usage data from the execution to produce a detailed report at the end. \figref{fig:profiler-sample} shows a profiling report for the program in \autoref{code:prof-mean}.

\begin{figure}[htp]
  \centering
  \caption{An example of report generated by the \ac{ghc} profiler}
  \includegraphics[width=\columnwidth]{images/profiler-placeholder}
  \footnotesize{Source: Made by the author.}
  \label{fig:profiler-sample}
\end{figure}

As we can see in this example, we can split the report into three different sections. The first one is the header. It shows how the program was executed (which flags and arguments were passed to run it), and the total time and memory allocated during the whole execution of the program. The second part shows a break-down of the most costly cost centres. In this case, the top-level \texttt{MAIN} and the user-defined \texttt{mean}.

The third section shows a break-down by \emph{cost centre stack}~\citep{morgan:1998}. A cost centre stack is similar to a call graph. It defines a hierarchy of cost centres. In this case, we can see that \texttt{MAIN} is the root of the cost centre stack, followed by \texttt{mean} and some instances of \texttt{CAF} as children. A \ac{caf} is an expression that contains no free variables, i.e. it is a constant expression. So a \texttt{CAF} cost centre represents the one-off costs of evaluating such constants. Also, in this section of the report, we have multiple columns showing the profiling data. The time and memory usage percentage columns are shown into two different groups: \texttt{individual} and \texttt{inherited}. The former is the total of program resources spent by this cost centre while the latter is the total of program resources spent by this cost centre and its children. The other columns are \texttt{no.}, which is the id of the cost centre, and \texttt{entries}, which is the number of times that the expression enclosed by this cost centre was evaluated.

So to help on our journey of understanding the energy behavior of Haskell programs, we have extended the \ac{ghc} profiler to add a new metric: energy consumption. The idea is to collect energy consumption readings from \ac{rapl} and use the \ac{ghc} infrastructure to calculate the energy spent by each cost centre. Having this, we can display two new columns in the final report accounting the percentage of energy consumed by each cost centre. We based our solution on the approach used by the time profiler. To measure the execution time, the profiler keeps in each cost centre a tick counter. At any moment, the cost centre that is currently executing is held in a special register by the runtime system. Then, a regular clock interrupt\footnote{By default this interval is 20ms. However, the user can change it by passing a custom value to the runtime system via the \texttt{-V} argument.} runs a routine to increment this tick counter of the cost centre in execution. At the end of the program execution, the value held in the tick counter of each cost centre enables the profiler to determine and report the relative execution time cost of the different parts of the program.

Similarly, our extended version of the \ac{ghc} profiler keeps in each cost centre an accumulator. At each clock interrupt, the profiler adds to the accumulator of the cost centre that is currently in execution the energy consumed between the previous and current interrupt. This is accomplished by always saving the previous and current energy readings obtained from \ac{rapl}. At the end of the program execution, the profiler will be able to report the energy consumed by each cost centre based on its accumulator value. \figref{fig:energy-prof-report} shows the report of our extended GHC profiler the same program from \autoref{code:prof-mean}. As we can see in this report, we have now energy consumption information on each section of the report. In the header, we have the total energy consumed during the execution of the program. In the second and third sections we have extra columns showing the percentage of energy consumed by each cost centres.

\begin{figure}[htp]
  \centering
  \caption{An example of report generated by the \ac{ghc} profiler with energy metrics}
  \includegraphics[width=\columnwidth]{images/energy-profiler-placeholder}
  \footnotesize{Source: Made by the author.}
  \label{fig:energy-prof-report}
\end{figure}

Our modified version of \ac{ghc} is publicly available on GitHub\footnote{\url{http://github.com/green-haskell/ghc/tree/wip/green}}. It is based on \ac{ghc} 7.10 and includes the profiler with energy metrics. However, it is important to note that our implementation has one limitation. We can provide more accurate results only for programs that use a single capability. The main reason for this is the fact that \ac{rapl} does not provide the energy consumed by a single core. It provides only the energy consumption of the cores altogether, so if two cost centres are executing in parallel, we cannot tell how much energy each one consumed separately. However, we could easily adapt the current implementation to handle this case once the underlying \ac{api} provides the energy by core information. Also, it is easy enough to change the use of \ac{rapl} for another \ac{api} that provides energy consumption information if needed.

Despite this limitation, the profiler tool is particularly useful for providing fine-grained information about energy consumption. It enables developers to find the energy hot spots of Haskell programs. In the next section, we present another performance analysis tool called Criterion. Different from a profiler, it uses a coarse-grained approach for evaluating the performance of a program.


\section{Criterion}\label{sec:criterion}
Criterion~\citep{sullivan:2009} is a microbenchmarking library that is used to measure the performance of Haskell code. Its main objective is to estimate the cost of running a small, independent piece of code. At a first glance, it may seem that it does the same job of a profiler, but this is not the case. Criterion is not designed to finding hot spots in a program. Instead, it is useful for analyzing the cost of a given operation. A profiler is about taking a snapshot of a single execution of a program and reporting fine-grained information about its performance. Criterion, however, is about running a certain piece of code several times to analyze its performance. It reports to the developer a statistically-backed estimation of the cost of running the selected piece of code. As Criterion does not analyze the performance of each cost centre, only the benchmarked code as a whole, we say its analysis is coarse-grained.

Criterion provides a framework for both executing benchmarks as well as analysing their results. This framework is based on a simple \ac{api} that hides most of the complexity of performing benchmarks. In \autoref{code:fib-crit}\footnote{This example was extracted from \url{http://www.serpentine.com/criterion/tutorial.html}}, we show an example of how to define a Criterion benchmark. Here, we want to analyse the performance of the \texttt{fib} function. The benchmark is defined to execute \texttt{fib} passing 9 as argument. We provide the Criterion \ac{api} in details on \appref{ap:criterion}. Here in this example, we are using three important function of its \ac{api}:
\begin{itemize}
  \item \texttt{defaultMain}: takes care of executing a set of benchmarks
  \item \texttt{bench}: creates a benchmark based on an action provided by the developer
  \item \texttt{whnf}: makes sure the benchmarked action is evaluated to weak head normal form to avoid it to be evaluated only once due to Haskell's laziness
\end{itemize}

\begin{listing}
  \caption{Benchmark definition for a \texttt{fib} function using Criterion}
  \begin{minted}{haskell}
import Criterion.Main

fib :: Int -> Int
fib m | m < 0     = error "negative!"
      | otherwise = go m
  where
    go 0 = 0
    go 1 = 1
    go n = go (n-1) + go (n-2)

main :: IO ()
main = defaultMain [
    bench "fib/9" (whnf fib 9)
  ]
  \end{minted}
  \label{code:fib-crit}
\end{listing}

In \figref{fig:fib-output}, we show the output for the benchmark described by \autoref{code:fib-crit}.

\begin{figure}[htp]
  \centering
  \caption{Program output for \autoref{code:fib-crit}}
  \begin{Verbatim}[fontsize=\small]
benchmarking fib/9
time                 315.8 ns   (314.3 ns .. 318.4 ns)
                     1.000 R²   (0.999 R² .. 1.000 R²)
mean                 319.1 ns   (317.2 ns .. 321.1 ns)
std dev              6.546 ns   (6.026 ns .. 7.283 ns)
variance introduced by outliers: 26% (moderately inflated)
  \end{Verbatim}
  \footnotesize{Source: Made by the author.}
  \label{fig:fib-output}
\end{figure}
